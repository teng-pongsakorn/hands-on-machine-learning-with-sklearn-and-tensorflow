{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=None):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 268435456, 15917525426429477155),\n",
       " _DeviceAttributes(/job:localhost/replica:0/task:0/device:GPU:0, GPU, 3168180633, 14077114956586335782)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.list_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Managing the GPU RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.gpu_options.per_process_gpu_memory_fraction = .4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another option\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placing Operations on Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.Variable(3.0)\n",
    "    b = tf.Variable(4.0)\n",
    "\n",
    "c = a * b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', '/device:CPU:0', '/device:CPU:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.device, a.device, b.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logging placements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable/initial_value /device:CPU:0 Const\n",
      "Variable /device:CPU:0 VariableV2\n",
      "Variable/Assign /device:CPU:0 Assign\n",
      "Variable/read /device:CPU:0 Identity\n",
      "Variable_1/initial_value /device:CPU:0 Const\n",
      "Variable_1 /device:CPU:0 VariableV2\n",
      "Variable_1/Assign /device:CPU:0 Assign\n",
      "Variable_1/read /device:CPU:0 Identity\n",
      "mul  Mul\n"
     ]
    }
   ],
   "source": [
    "for op in sess.graph.get_operations():\n",
    "    print(op.name, op.device, op.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.initializer.run(session=sess)\n",
    "b.initializer.run(session=sess)\n",
    "\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dynamic placement function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "\n",
    "def variables_on_cpu(op):\n",
    "    if op.name.startswith('Variable'):\n",
    "        return '/cpu:0'\n",
    "    return '/gpu:0'\n",
    "\n",
    "with tf.device(variables_on_cpu):\n",
    "    a = tf.Variable(4.0)\n",
    "    b = tf.Variable(3.0)\n",
    "    \n",
    "    c = a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/cpu:0', '/cpu:0', '/gpu:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device, b.device, c.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soft placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    i = tf.Variable(3)\n",
    "    \n",
    "config = tf.ConfigProto()\n",
    "config.allow_soft_placement = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "sess.run(i.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/device:GPU:0', tf.int32_ref)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.device, i.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.inter_op_parallelism_threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.intra_op_parallelism_threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Local Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "c = tf.constant('Hello distributed tensorflow!')\n",
    "server = tf.train.Server.create_local_server()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is a convenience wrapper for creating a\n",
    "`tf.train.Server` with a `tf.train.ServerDef` that specifies a\n",
    "single-process cluster containing a single task in a job called\n",
    "`\"local\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello distributed tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "# server.target -> Returns the target for a `tf.Session` to connect to this server\n",
    "with tf.Session(target=server.target) as sess:\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'grpc://localhost:59232'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.train.ClusterSpec() -> Represents a cluster as a set of \"tasks\", organized into \"jobs\".\n",
    "cluster_spec = tf.train.ClusterSpec({\n",
    "    'ps': [\n",
    "        '127.0.0.1:2221',      # /job:ps/task:0\n",
    "        '127.0.0.1:2222',      # /job:ps/task:1\n",
    "    ],\n",
    "    'worker': [\n",
    "        '127.0.0.1:2223',       # /job:worker/task:0\n",
    "        '127.0.0.1:2224',       # /job:worker/task:1\n",
    "        '127.0.0.1:2225',       # /job:worker/task:2\n",
    "    ],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ps0 = tf.train.Server(cluster_spec, job_name='ps', task_index=0)\n",
    "task_ps1 = tf.train.Server(cluster_spec, job_name='ps', task_index=1)\n",
    "task_worker0 = tf.train.Server(cluster_spec, job_name='worker', task_index=0)\n",
    "task_worker1 = tf.train.Server(cluster_spec, job_name='worker', task_index=1)\n",
    "task_worker2 = tf.train.Server(cluster_spec, job_name='worker', task_index=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pinning operations across devices and servers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.device(\"/job:ps\"):\n",
    "    a = tf.Variable(3.0, name='a')\n",
    "    \n",
    "with tf.device('/job:worker'):\n",
    "    b = a + 3\n",
    "    \n",
    "with tf.device('/job:worker/task:1'):\n",
    "    c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'grpc://localhost:2221'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_ps0.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(task_worker0.target) as sess:\n",
    "    sess.run(a.initializer)\n",
    "    print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0 6.0 9.0\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "with tf.device(tf.train.replica_device_setter(cluster=cluster_spec)):\n",
    "    v1 = tf.Variable(1.0)\n",
    "    v2 = tf.Variable(2.0)\n",
    "    v3 = tf.Variable(3.0)\n",
    "    v4 = tf.Variable(4.0)\n",
    "    v5 = tf.Variable(5.0)\n",
    "    \n",
    "    s = v1 + v2\n",
    "    with tf.device('/task:1'):\n",
    "        p1 = 2 * s\n",
    "    with tf.device('/cpu:0'):\n",
    "        p2 = 3 * s\n",
    "        \n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "\n",
    "with tf.Session(target=task_ps0.target, config=config) as sess:\n",
    "    sess.run([v1.initializer, v2.initializer])\n",
    "    print(s.eval(), p1.eval(), p2.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/job:ps/task:0',\n",
       " '/job:ps/task:1',\n",
       " '/job:ps/task:0',\n",
       " '/job:ps/task:1',\n",
       " '/job:ps/task:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.device, v2.device, v3.device, v4.device, v5.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/job:worker', '/job:worker/task:1', '/job:worker/device:CPU:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.device, p1.device, p2.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reader - the old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('my_test.csv', 'w') as f:\n",
    "    f.write('x1, x2, target\\n')\n",
    "    f.write('1., 2., 0\\n')\n",
    "    f.write('4., 5, 1\\n')\n",
    "    f.write('7., , 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more files to read\n",
      "[array([[4., 5.],\n",
      "       [7., 0.]], dtype=float32), array([1, 0])]\n",
      "[array([[1., 2.]], dtype=float32), array([0])]\n",
      "no more instances to read\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "# filename queue\n",
    "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "filename = tf.placeholder(dtype=tf.string, shape=())\n",
    "enqueue_filename = filename_queue.enqueue([filename])\n",
    "close_filename_queue = filename_queue.close()\n",
    "\n",
    "# reader\n",
    "reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, val = reader.read(filename_queue)\n",
    "x1, x2, target = tf.decode_csv(val, record_defaults=[[-1.], [-1.], [-1]])\n",
    "features = tf.stack([x1, x2])\n",
    "\n",
    "# instance queue\n",
    "instance_queue = tf.RandomShuffleQueue(capacity=10, min_after_dequeue=2, \n",
    "                                       dtypes=[tf.float32, tf.int32], \n",
    "                                       shapes=[[2], []], name='instance_q', \n",
    "                                       shared_name='shared_instance_q')\n",
    "enqueue_instace = instance_queue.enqueue([features, target])\n",
    "close_instance_queue = instance_queue.close()\n",
    "\n",
    "# dequeue \n",
    "minibatch_features, minibatch_target = instance_queue.dequeue_up_to(n=2)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(enqueue_filename, feed_dict={filename:'my_test.csv'})\n",
    "    sess.run(close_filename_queue)\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            sess.run(enqueue_instace)\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print('no more files to read')\n",
    "    sess.run(close_instance_queue)\n",
    "        \n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([minibatch_features, minibatch_target]))\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print('no more instances to read')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Queue runners and coordinators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 2.],\n",
      "       [4., 5.]], dtype=float32), array([0, 1])]\n",
      "[array([[7., 0.]], dtype=float32), array([0])]\n",
      "no more file to read\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "\n",
    "# filename queue\n",
    "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "filename = tf.placeholder(tf.string, [])\n",
    "enqueue_filename = filename_queue.enqueue([filename])\n",
    "close_filename_queue = filename_queue.close()\n",
    "\n",
    "# file reader\n",
    "line_reader = tf.TextLineReader(skip_header_lines=1)\n",
    "key, value = line_reader.read(filename_queue)\n",
    "x1, x2, target = tf.decode_csv(value, record_defaults=[[-1.], [-1.], [-1]])\n",
    "features = tf.stack([x1, x2])\n",
    "\n",
    "# instance queue\n",
    "instance_queue = tf.RandomShuffleQueue(capacity=10, dtypes=[tf.float32, tf.int32], shapes=[[2],[]], \n",
    "                                       min_after_dequeue=2, name='instance_q', shared_name='shared_instance_q')\n",
    "enqueue_instance = instance_queue.enqueue([features, target])\n",
    "close_instance_queue = instance_queue.close()\n",
    "\n",
    "# instance dequeue\n",
    "minibatch_features, minibatch_target = instance_queue.dequeue_up_to(2)\n",
    "\n",
    "# queue runner & coordinator\n",
    "num_threads = 4\n",
    "coord = tf.train.Coordinator()\n",
    "queue_runner = tf.train.QueueRunner(instance_queue, [enqueue_instance]*num_threads)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(enqueue_filename, feed_dict={filename: 'my_test.csv'})\n",
    "    sess.run(close_filename_queue)\n",
    "    enqueue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([minibatch_features, minibatch_target]))\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print('no more file to read')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[1., 2.],\n",
      "       [7., 0.]], dtype=float32), array([0, 0])]\n",
      "[array([[4., 5.]], dtype=float32), array([1])]\n",
      "no more file to read\n"
     ]
    }
   ],
   "source": [
    "# read multiple files simultaneously\n",
    "reset_graph()\n",
    "\n",
    "# filename queue\n",
    "filename_queue = tf.FIFOQueue(capacity=10, dtypes=[tf.string], shapes=[()])\n",
    "filename = tf.placeholder(tf.string, [])\n",
    "enqueue_filename = filename_queue.enqueue([filename])\n",
    "close_filename_queue = filename_queue.close()\n",
    "\n",
    "# instance queue\n",
    "instance_queue = tf.RandomShuffleQueue(capacity=10, dtypes=[tf.float32, tf.int32], shapes=[[2], []], \n",
    "                                       min_after_dequeue=2, name='instance_q', shared_name='shared_instance_q')\n",
    "close_instance_queue = instance_queue.close()\n",
    "minibatch_features, minibatch_target = instance_queue.dequeue_up_to(2)\n",
    "\n",
    "# read multi-file operations\n",
    "def read_push_instance(filename_queue, instance_queue):\n",
    "    reader = tf.TextLineReader(skip_header_lines=1)\n",
    "    key, values = reader.read(filename_queue)\n",
    "    x1, x2, target = tf.decode_csv(values, record_defaults=[[-1.], [-1.], [-1]])\n",
    "    features = tf.stack([x1, x2])\n",
    "    enqueue_instance = instance_queue.enqueue([features, target])\n",
    "    return enqueue_instance\n",
    "\n",
    "read_and_enqueue_ops = [read_push_instance(filename_queue, instance_queue) \n",
    "                        for i in range(5)]\n",
    "coord = tf.train.Coordinator()\n",
    "queue_runner = tf.train.QueueRunner(instance_queue, read_and_enqueue_ops)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(enqueue_filename, feed_dict={filename: 'my_test.csv'})\n",
    "    sess.run(close_filename_queue)\n",
    "    \n",
    "    queue_threads = queue_runner.create_threads(sess, coord=coord, start=True)\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([minibatch_features, minibatch_target]))\n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print('no more file to read')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "\n",
    "data = data.repeat(3).batch(7)\n",
    "\n",
    "iterator = data.make_one_shot_iterator()\n",
    "\n",
    "next_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 2, 3, 4, 5, 6]), array([0, 1, 2, 3, 4, 5, 6])]\n",
      "[array([7, 8, 9, 0, 1, 2, 3]), array([7, 8, 9, 0, 1, 2, 3])]\n",
      "[array([4, 5, 6, 7, 8, 9, 0]), array([4, 5, 6, 7, 8, 9, 0])]\n",
      "[array([1, 2, 3, 4, 5, 6, 7]), array([1, 2, 3, 4, 5, 6, 7])]\n",
      "[array([8, 9]), array([8, 9])]\n",
      "out of data\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run([next_batch, next_batch]))\n",
    "            \n",
    "    except tf.errors.OutOfRangeError as ex:\n",
    "        print(\"out of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = tf.data.Dataset.from_tensor_slices(np.arange(10))\n",
    "data = data.repeat(3).batch(7)\n",
    "data = data.interleave(lambda v: tf.data.Dataset.from_tensor_slices(v), cycle_length=3, block_length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = data.make_one_shot_iterator()\n",
    "next_elements = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 1, 7, 8, 4, 5, 2, 3, 9, 0, 6, 7, 4, 5, 1, 2, 8, 9, 6, 3, 0, 1, 2, 8, 9, 3, 4, 5, 6, 7, done\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            print(sess.run(next_elements), end=', ')\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Readers – the new way\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "dataset = tf.data.TextLineDataset(['my_test.csv'])\n",
    "\n",
    "def reader(line):\n",
    "    x1, x2, y = tf.decode_csv(line, record_defaults=[[-1.], [-1.], [-1]])\n",
    "    x = tf.stack([x1, x2])\n",
    "    return x, y\n",
    "\n",
    "dataset = dataset.skip(1).map(reader)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "X, y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.] 0\n",
      "[4. 5.] 1\n",
      "[7. 0.] 0\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        while True:\n",
    "            a, b = sess.run([X, y])\n",
    "            print(a, b)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
